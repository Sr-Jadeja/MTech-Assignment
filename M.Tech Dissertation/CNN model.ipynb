{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19f3bf28-d1ee-485b-8a87-5b0dee6927c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1452d17c-2147-4bc6-b738-65700db49d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DigitCSVTrain(Dataset):\n",
    "    def __init__(self, path):\n",
    "        df = pd.read_csv(path)\n",
    "        self.labels = df.iloc[:, 0].values\n",
    "        self.images = df.iloc[:, 1:].values.reshape(-1, 1, 28, 28).astype(\"float32\") / 255.0\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = torch.tensor(self.images[idx])\n",
    "        y = torch.tensor(self.labels[idx]).long()\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9737ace0-79ef-486a-b38a-1f670e1f32ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DigitCSVTest(Dataset):\n",
    "    def __init__(self, path):\n",
    "        df = pd.read_csv(path)\n",
    "        self.images = df.values.reshape(-1, 1, 28, 28).astype(\"float32\") / 255.0\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = torch.tensor(self.images[idx])\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "659872aa-a2b7-47c2-9401-1dd2c46f6d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNeXtBlock(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.dw = nn.Conv2d(dim, dim, kernel_size=7, padding=3, groups=dim)\n",
    "        self.bn = nn.BatchNorm2d(dim)\n",
    "        self.act = nn.GELU()\n",
    "        self.pw = nn.Conv2d(dim, dim, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.dw(x)\n",
    "        out = self.bn(out)\n",
    "        out = self.act(out)\n",
    "        out = self.pw(out)\n",
    "        return x + out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e104c27-ed79-4f3f-95ea-58e9d4660a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNeXtTiny(nn.Module):\n",
    "    def __init__(self, in_ch=1, num_classes=10):\n",
    "        super().__init__()\n",
    "\n",
    "        self.stem = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, 96, kernel_size=4, stride=4),\n",
    "            nn.BatchNorm2d(96),\n",
    "            nn.GELU()\n",
    "        )\n",
    "\n",
    "        self.stage1 = nn.Sequential(\n",
    "            ConvNeXtBlock(96),\n",
    "            ConvNeXtBlock(96),\n",
    "            ConvNeXtBlock(96)\n",
    "        )\n",
    "\n",
    "        self.down1 = nn.Conv2d(96, 192, kernel_size=2, stride=2)\n",
    "\n",
    "        self.stage2 = nn.Sequential(\n",
    "            ConvNeXtBlock(192),\n",
    "            ConvNeXtBlock(192),\n",
    "            ConvNeXtBlock(192)\n",
    "        )\n",
    "\n",
    "        self.down2 = nn.Conv2d(192, 384, kernel_size=2, stride=2)\n",
    "\n",
    "        self.stage3 = nn.Sequential(\n",
    "            *[ConvNeXtBlock(384) for _ in range(9)]\n",
    "        )\n",
    "\n",
    "        self.stage4 = nn.Sequential(\n",
    "            ConvNeXtBlock(384),\n",
    "            ConvNeXtBlock(384),\n",
    "            ConvNeXtBlock(384)\n",
    "        )\n",
    "\n",
    "        self.pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Linear(384, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.stem(x)\n",
    "        x = self.stage1(x)\n",
    "        x = self.down1(x)\n",
    "\n",
    "        x = self.stage2(x)\n",
    "        x = self.down2(x)\n",
    "\n",
    "        x = self.stage3(x)\n",
    "\n",
    "        x = self.stage4(x)\n",
    "\n",
    "        x = self.pool(x).flatten(1)\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd130325-61dc-4485-9fc7-0e8222d25eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = r\"C:\\Users\\Public\\Documents\\NITJ\\Research MTech\\digit-recognizer\\train.csv\"\n",
    "test_path  = r\"C:\\Users\\Public\\Documents\\NITJ\\Research MTech\\digit-recognizer\\test.csv\"\n",
    "\n",
    "train_dataset = DigitCSVTrain(train_path)\n",
    "test_dataset  = DigitCSVTest(test_path)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8fcfcf6d-23ba-40c1-be5e-567416861c99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: loss=0.2535, acc=0.9301\n",
      "Epoch 2: loss=0.1004, acc=0.9698\n",
      "Epoch 3: loss=0.0812, acc=0.9763\n",
      "Epoch 4: loss=0.0784, acc=0.9779\n",
      "Epoch 5: loss=0.0598, acc=0.9827\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = ConvNeXtTiny(in_ch=1, num_classes=10).to(device)\n",
    "opt = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "epochs = 5\n",
    "\n",
    "for e in range(epochs):\n",
    "    model.train()\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    loss_sum = 0\n",
    "\n",
    "    for x, y in train_loader:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        opt.zero_grad()\n",
    "        out = model(x)\n",
    "        loss = loss_fn(out, y)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        loss_sum += loss.item() * x.size(0)\n",
    "        correct += (out.argmax(1) == y).sum().item()\n",
    "        total += x.size(0)\n",
    "\n",
    "    print(f\"Epoch {e+1}: loss={loss_sum/total:.4f}, acc={correct/total:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ae0f6621-b054-4cb9-ac6f-0f7260937ca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved!\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(model, 'CNN_digit_recognizer.pkl')\n",
    "print(\"Model saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f353abee-eb69-43bc-861b-28b4dda3c078",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully via Joblib\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "# 2. Load the model\n",
    "# Note: You must have the Class definitions (ConvNeXtTiny, ConvNeXtBlock) \n",
    "# defined in the script before running this.\n",
    "loaded_model = joblib.load('CNN_digit_recognizer.pkl')\n",
    "\n",
    "# 3. Set to evaluation mode (Important for BatchNorm layers)\n",
    "loaded_model.eval()\n",
    "\n",
    "print(\"Model loaded successfully via Joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "25b3a093-49d6-4d05-a9df-51af6967913f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking accuracy with different Hyperparameter\n",
    "def run_experiment(\n",
    "    lr,\n",
    "    batch_size,\n",
    "    epochs,\n",
    "    blocks_stage3 \n",
    "):\n",
    "    print(\"\\n==== Running Experiment ====\")\n",
    "    print(f\"Learning Rate: {lr}\")\n",
    "    print(f\"Batch Size: {batch_size}\")\n",
    "    print(f\"Epochs: {epochs}\")\n",
    "    print(f\"Stage3 Blocks: {blocks_stage3}\")\n",
    "\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "    train_path = r\"C:\\Users\\Public\\Documents\\NITJ\\Research MTech\\digit-recognizer\\train.csv\"\n",
    "    train_dataset = DigitCSVTrain(train_path)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    # ---- Create model normally ----\n",
    "    model = ConvNeXtTiny(in_ch=1, num_classes=10)\n",
    "\n",
    "    # ---- Modify stage3 dynamically based on user input ----\n",
    "    model.stage3 = nn.Sequential(*[ConvNeXtBlock(384) for _ in range(blocks_stage3)])\n",
    "\n",
    "    model = model.to(device)\n",
    "\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    for e in range(epochs):\n",
    "        model.train()\n",
    "        total = 0\n",
    "        correct = 0\n",
    "        loss_sum = 0\n",
    "\n",
    "        for x, y in train_loader:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            opt.zero_grad()\n",
    "            out = model(x)\n",
    "            loss = loss_fn(out, y)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "            loss_sum += loss.item() * x.size(0)\n",
    "            correct += (out.argmax(1) == y).sum().item()\n",
    "            total += x.size(0)\n",
    "\n",
    "        print(f\"Epoch {e+1}/{epochs} — Loss: {loss_sum/total:.4f}, Acc: {correct/total:.4f}\")\n",
    "\n",
    "    print(\"Training complete!\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0f0e098b-3875-445e-9139-bf399251be81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== Running Experiment ====\n",
      "Learning Rate: 0.0005\n",
      "Batch Size: 256\n",
      "Epochs: 3\n",
      "Stage3 Blocks: 3\n",
      "Epoch 1/3 — Loss: 0.2001, Acc: 0.9371\n",
      "Epoch 2/3 — Loss: 0.0754, Acc: 0.9761\n",
      "Epoch 3/3 — Loss: 0.0379, Acc: 0.9879\n",
      "Training complete!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_experiment(\n",
    "    lr=0.0005,\n",
    "    batch_size=256,\n",
    "    epochs=3,\n",
    "    blocks_stage3=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2bd39aee-7924-4443-a7f8-f023dc250190",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== Running Experiment ====\n",
      "Learning Rate: 0.001\n",
      "Batch Size: 384\n",
      "Epochs: 2\n",
      "Stage3 Blocks: 1\n",
      "Epoch 1/2 — Loss: 0.2004, Acc: 0.9374\n",
      "Epoch 2/2 — Loss: 0.0593, Acc: 0.9810\n",
      "Training complete!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_experiment(\n",
    "    lr=0.001,\n",
    "    batch_size=384,\n",
    "    epochs=2,\n",
    "    blocks_stage3=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d17ea72-e544-4d24-af87-ab94323403d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== Running Experiment ====\n",
      "Learning Rate: 0.002\n",
      "Batch Size: 512\n",
      "Epochs: 2\n",
      "Stage3 Blocks: 2\n",
      "Epoch 1/2 — Loss: 0.2681, Acc: 0.9202\n",
      "Epoch 2/2 — Loss: 0.0875, Acc: 0.9741\n",
      "Training complete!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_experiment(\n",
    "    lr=0.002,\n",
    "    batch_size=512,\n",
    "    epochs=2,\n",
    "    blocks_stage3=2\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
